{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jewel/opt/anaconda3/envs/nvidiatest/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_statics.py:319: UserWarning: Model ai-mixtral-8x7b-instruct is deprecated. Using mistralai/mixtral-8x7b-instruct-v0.1 instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatNVIDIA(model=\"ai-mixtral-8x7b-instruct\", max_tokens=1000) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def index_docs(url, splitter, documents, dest_embed_dir) -> None:\n",
    "    \"\"\"\n",
    "    Split the document into chunks and create embeddings for the document\n",
    "\n",
    "    Args:\n",
    "        url: Source url for the document.\n",
    "        splitter: Splitter used to split the document\n",
    "        documents: list of documents whose embeddings needs to be created\n",
    "        dest_embed_dir: destination directory for embeddings\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "from PyPDF2 import PdfReader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import re\n",
    "\n",
    "# Input for dir_path is './<dir name>'\n",
    "def batch_document_reader(dir_path):\n",
    "\n",
    "    # Getting filenames in the directory\n",
    "    filenames = [f for f in listdir(dir_path) if isfile(join(dir_path, f))]\n",
    "\n",
    "    documents = []\n",
    "    for pdf in filenames:\n",
    "        pdf_reader = PdfReader(dir_path + '/' + pdf)\n",
    "        \n",
    "        print(f\"Reading document: {pdf}\")\n",
    "        text = \"\"\n",
    "        for page in pdf_reader.pages:\n",
    "            text += page.extract_text()\n",
    "        \n",
    "        # Remove excess whitespace and newlines\n",
    "        text = re.sub(\"\\s+\", \" \", text).strip()\n",
    "\n",
    "        documents.append(text)\n",
    "        \n",
    "    text_splitter = RecursiveCharacterTextSplitter(\n",
    "        chunk_size=1000,\n",
    "        chunk_overlap=0,\n",
    "        length_function=len,\n",
    "    )\n",
    "    \n",
    "    texts = text_splitter.create_documents(documents)\n",
    "    print(len(texts))\n",
    "        \n",
    "    return texts, text_splitter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "def create_embeddings(documents, splitter, embedding_path):\n",
    "\n",
    "    # embedding_path = \"./embed\"\n",
    "    print(f\"Storing embeddings to filepath {embedding_path}\")\n",
    "\n",
    "    embeddings = NVIDIAEmbeddings(model=\"nvolveqa_40k\")\n",
    "\n",
    "    for document in documents:\n",
    "        \n",
    "        texts = splitter.split_text(document.page_content)\n",
    "\n",
    "        # metadata to attach to document\n",
    "        metadatas = [document.metadata]\n",
    "\n",
    "        # create embeddings and add to vector store\n",
    "        if os.path.exists(embedding_path):\n",
    "            update = FAISS.load_local(folder_path=embedding_path, embeddings=embeddings, allow_dangerous_deserialization=True)\n",
    "            update.add_texts(texts, metadatas=metadatas)\n",
    "            update.save_local(folder_path=embedding_path)\n",
    "        else:\n",
    "            docsearch = FAISS.from_texts(texts, embedding=embeddings, metadatas=metadatas)\n",
    "            docsearch.save_local(folder_path=embedding_path)\n",
    "\n",
    "    print(\"Generated embedding successfully\")\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading document: Models.pdf\n",
      "Reading document: Transport.pdf\n",
      "Reading document: textbook.pdf\n",
      "537\n",
      "Storing embeddings to filepath ./embed\n",
      "Generated embedding successfully\n"
     ]
    }
   ],
   "source": [
    "texts, text_splitter = batch_document_reader(\"./pdf_samples\")\n",
    "create_embeddings(texts, text_splitter, \"./embed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RUN FROM HERE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jewel/opt/anaconda3/envs/nvidiatest/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_statics.py:319: UserWarning: Model nvolveqa_40k is deprecated. Using NV-Embed-QA instead.\n",
      "  warnings.warn(\n",
      "/Users/jewel/opt/anaconda3/envs/nvidiatest/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/embeddings.py:87: UserWarning: Setting truncate=\"END\" for nvolveqa_40k backward compatibility\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# loading the \n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "embedding_model = NVIDIAEmbeddings(model=\"nvolveqa_40k\")\n",
    "docsearch = FAISS.load_local(folder_path=\"./embed\", embeddings=embedding_model, allow_dangerous_deserialization=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jewel/opt/anaconda3/envs/nvidiatest/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_statics.py:319: UserWarning: Model ai-mixtral-8x7b-instruct is deprecated. Using mistralai/mixtral-8x7b-instruct-v0.1 instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from langchain_nvidia_ai_endpoints import ChatNVIDIA\n",
    "from langchain.memory import ConversationBufferMemory\n",
    "from langchain.chains import ConversationalRetrievalChain, LLMChain\n",
    "from langchain.chains.conversational_retrieval.prompts import CONDENSE_QUESTION_PROMPT, QA_PROMPT\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()\n",
    "\n",
    "llm = ChatNVIDIA(model=\"ai-mixtral-8x7b-instruct\", temperature=0.1, max_tokens=1000, top_p=1.0)\n",
    "\n",
    "memory = ConversationBufferMemory(memory_key=\"chat_history\", return_messages=True)\n",
    "\n",
    "qa_prompt=QA_PROMPT\n",
    "\n",
    "doc_chain = load_qa_chain(llm, chain_type=\"stuff\", prompt=QA_PROMPT)\n",
    "\n",
    "qa = ConversationalRetrievalChain.from_llm(\n",
    "    llm=llm,\n",
    "    retriever=docsearch.as_retriever(),\n",
    "    chain_type=\"stuff\",\n",
    "    memory=memory,\n",
    "    combine_docs_chain_kwargs={'prompt': qa_prompt},\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jewel/opt/anaconda3/envs/nvidiatest/lib/python3.10/site-packages/langchain_core/_api/deprecation.py:119: LangChainDeprecationWarning: The method `Chain.__call__` was deprecated in langchain 0.1.0 and will be removed in 0.3.0. Use invoke instead.\n",
      "  warn_deprecated(\n"
     ]
    }
   ],
   "source": [
    "query = \"What is the Aloha Network?\"\n",
    "result = qa({\"question\": query})\n",
    "print(result.get(\"answer\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "query = \"Explain it to a 5 year old.\"\n",
    "result = qa({\"question\": query})\n",
    "print(result.get(\"answer\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n",
      "Intel MKL WARNING: Support of Intel(R) Streaming SIMD Extensions 4.2 (Intel(R) SSE4.2) enabled only processors has been deprecated. Intel oneAPI Math Kernel Library 2025.0 will require Intel(R) Advanced Vector Extensions (Intel(R) AVX) instructions.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/jewel/opt/anaconda3/envs/nvidiatest/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/_statics.py:319: UserWarning: Model nvolveqa_40k is deprecated. Using NV-Embed-QA instead.\n",
      "  warnings.warn(\n",
      "/Users/jewel/opt/anaconda3/envs/nvidiatest/lib/python3.10/site-packages/langchain_nvidia_ai_endpoints/embeddings.py:87: UserWarning: Setting truncate=\"END\" for nvolveqa_40k backward compatibility\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.).",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 10\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parsers\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m StrOutputParser\n\u001b[1;32m      8\u001b[0m embedding_model \u001b[38;5;241m=\u001b[39m NVIDIAEmbeddings(model\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnvolveqa_40k\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m---> 10\u001b[0m store \u001b[38;5;241m=\u001b[39m \u001b[43mFAISS\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_local\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m./embed\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43membedding_model\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     12\u001b[0m retriever \u001b[38;5;241m=\u001b[39m store\u001b[38;5;241m.\u001b[39mas_retriever()\n\u001b[1;32m     14\u001b[0m prompt \u001b[38;5;241m=\u001b[39m ChatPromptTemplate\u001b[38;5;241m.\u001b[39mfrom_messages(\n\u001b[1;32m     15\u001b[0m     [\n\u001b[1;32m     16\u001b[0m         (\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     21\u001b[0m     ]\n\u001b[1;32m     22\u001b[0m )\n",
      "File \u001b[0;32m~/opt/anaconda3/envs/nvidiatest/lib/python3.10/site-packages/langchain_community/vectorstores/faiss.py:1077\u001b[0m, in \u001b[0;36mFAISS.load_local\u001b[0;34m(cls, folder_path, embeddings, index_name, allow_dangerous_deserialization, **kwargs)\u001b[0m\n\u001b[1;32m   1063\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Load FAISS index, docstore, and index_to_docstore_id from disk.\u001b[39;00m\n\u001b[1;32m   1064\u001b[0m \n\u001b[1;32m   1065\u001b[0m \u001b[38;5;124;03mArgs:\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1074\u001b[0m \u001b[38;5;124;03m        arbitrary code on your machine.\u001b[39;00m\n\u001b[1;32m   1075\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   1076\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m allow_dangerous_deserialization:\n\u001b[0;32m-> 1077\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m   1078\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe de-serialization relies loading a pickle file. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1079\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPickle files can be modified to deliver a malicious payload that \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1080\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresults in execution of arbitrary code on your machine.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1081\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mYou will need to set `allow_dangerous_deserialization` to `True` to \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1082\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124menable deserialization. If you do this, make sure that you \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1083\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mtrust the source of the data. For example, if you are loading a \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1084\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile that you created, and know that no one else has modified the \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1085\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mfile, then this is safe to do. Do not set this to `True` if you are \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1086\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mloading a file from an untrusted source (e.g., some random site on \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1087\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe internet.).\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1088\u001b[0m     )\n\u001b[1;32m   1089\u001b[0m path \u001b[38;5;241m=\u001b[39m Path(folder_path)\n\u001b[1;32m   1090\u001b[0m \u001b[38;5;66;03m# load index separately since it is not picklable\u001b[39;00m\n",
      "\u001b[0;31mValueError\u001b[0m: The de-serialization relies loading a pickle file. Pickle files can be modified to deliver a malicious payload that results in execution of arbitrary code on your machine.You will need to set `allow_dangerous_deserialization` to `True` to enable deserialization. If you do this, make sure that you trust the source of the data. For example, if you are loading a file that you created, and know that no one else has modified the file, then this is safe to do. Do not set this to `True` if you are loading a file from an untrusted source (e.g., some random site on the internet.)."
     ]
    }
   ],
   "source": [
    "from langchain.vectorstores import FAISS\n",
    "from langchain_nvidia_ai_endpoints import NVIDIAEmbeddings\n",
    "\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.runnables import RunnablePassthrough\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "\n",
    "embedding_model = NVIDIAEmbeddings(model=\"nvolveqa_40k\")\n",
    "\n",
    "store = FAISS.load_local(\"./embed\", embedding_model)\n",
    "\n",
    "retriever = store.as_retriever()\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\n",
    "            \"system\",\n",
    "            \"Answer solely based on the following context:\\n<Documents>\\n{context}\\n</Documents>\",\n",
    "        ),\n",
    "        (\"user\", \"{question}\"),\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain = (\n",
    "    {\"context\": retriever, \"question\": RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | llm\n",
    "    | StrOutputParser()\n",
    ")\n",
    "\n",
    "chain.invoke(\"What is the Aloha Network?\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nvidiatest",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
